{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from numpy import expand_dims\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras import Sequential\n",
    "from keras.layers import *\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "train = pd.read_csv('/kaggle/input/mniststt/train.csv')\n",
    "test = pd.read_csv('/kaggle/input/mniststt/test.csv')\n",
    "sub = pd.read_csv('/kaggle/input/mniststt/submission.csv')\n",
    "\n",
    "# check the distribution of 'digit'\n",
    "train['digit'].value_counts()\n",
    "\n",
    "# drop columns\n",
    "train2 = train.drop(['id','digit','letter'],1)\n",
    "test2 = test.drop(['id','letter'],1)\n",
    "\n",
    "# convert pandas dataframe to numpy array\n",
    "train2 = train2.values\n",
    "test2 = test2.values\n",
    "\n",
    "plt.imshow(train2[100].reshape(28,28))\n",
    "\n",
    "train2 = train2.reshape(-1,28,28,1)\n",
    "test2 = test2.reshape(-1,28,28,1)\n",
    "\n",
    "# normalization\n",
    "train2 = train2/255.\n",
    "test2 = test2/255.\n",
    "\n",
    "# image data generator * data augmentation\n",
    "idg = ImageDataGenerator(height_shift_range = (-1,1), width_shift_range = (-1,1))\n",
    "idg2 = ImageDataGenerator()\n",
    "\n",
    "# show augmented image data\n",
    "sample_data = train2[100].copy()\n",
    "sample = expand_dims(sample_data,0)\n",
    "sample_datagen = ImageDataGenerator(height_shift_range=(-3,3), width_shift_range=(3,-3))\n",
    "sample_generator = sample_datagen.flow(sample, batch_size=1)\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    sample_batch = sample_generator.next()\n",
    "    sample_image = sample_batch[0]\n",
    "    plt.imshow(sample_image.reshape(28,28))\n",
    "\n",
    "# cross validation\n",
    "skf = StratifiedKFold(n_splits=40, random_state=42, shuffle=True)\n",
    "\n",
    "# patience 만큼의 epoch에도 벗어나지 못하면 callback 호출\n",
    "# verbose\n",
    "# factor: 학습률을 1/2로 줄인다 patience 만큼의 epoch에도 벗어나지 못하면 callback 호출\n",
    "reLR = ReduceLROnPlateau(monitor='accuracy',patience=100, verbose=1, factor=0.5)\n",
    "es = EarlyStopping(patience=160, verbose=1)\n",
    "\n",
    "val_loss_min = []\n",
    "result=0\n",
    "nth = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "for train_idx, valid_idx in tqdm(skf.split(train2,train['digit'])):\n",
    "    mc = ModelCheckpoint('best_cvision.h5', save_best_only=True, verbose=1)\n",
    "\n",
    "    x_train = train2[train_idx]\n",
    "    x_valid = train2[valid_idx]\n",
    "    y_train = train['digit'][train_idx]\n",
    "    y_valid = train['digit'][valid_idx]\n",
    "\n",
    "    train_generator = idg.flow(x_train, y_train, batch_size=8)\n",
    "    valid_generator = idg2.flow(x_valid, y_valid)\n",
    "    test_generator = idg2.flow(test2,shuffle=False)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16,(3,3), activation='relu', input_shape=(28,28,1),padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(32,(3,3),activation='relu',padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(32,(5,5),activation='relu',padding='same')) \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(32,(5,5),activation='relu',padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(32,(5,5),activation='relu',padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((3,3)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(64,(3,3),activation='relu',padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64,(5,5),activation='relu',padding='same')) \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((3,3)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(128,activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(64,activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    # model.compile(loss='sparse_categorical_crossentropy',optimizer=Adam(lr=0.002,epsilon=None), metrics=['acc'])\n",
    "    model.compile(loss='sparse_categorical_crossentropy',optimizer=Adam(lr=0.002,epsilon=None), metrics=['acc'])\n",
    "\n",
    "    # learning_history = model.fit_generator(train_generator, \n",
    "    #                                        epochs=2000, \n",
    "    #                                        validation_data=valid_generator,\n",
    "    #                                        callbacks=[es,mc,reLR])\n",
    "\n",
    "    learning_history = model.fit(train_generator, \n",
    "                                         epochs=2000, \n",
    "                                         validation_data=valid_generator,\n",
    "                                         callbacks=[es,mc,reLR])\n",
    "\n",
    "    # predict\n",
    "    model.load_weights('best_cvision.h5')\n",
    "    result += model.predict_generator(test_generator,verbose=True)\n",
    "\n",
    "    # save val_loss\n",
    "    hist = pd.DataFrame(learning_history.history)\n",
    "    val_loss_min.append(hist['val_loss'].min())\n",
    "\n",
    "    nth += 1\n",
    "    print(nth, '번째 학습을 완료했습니다.')\n",
    "\n",
    "display(val_loss_min, np.mean(val_loss_min))model.summary()\n",
    "\n",
    "sub.to_csv('result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['digit'] = result.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('Dacon_cvision_0914_40_epsNone.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
